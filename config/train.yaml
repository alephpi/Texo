output_dir: ${hydra:runtime.output_dir}

hydra:
  job:
    name: bs=${data.train_batch_size}-lr=${training.optimizer.lr}-freeze_backbone=${model.encoder.freeze_backbone}
  run:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}

model:
  tokenizer_path: ./data/tokenizer
  encoder:
    stem_channels: [3, 32, 48]
    stage_config:
      stage1: [48, 48, 128, 1, false, false, 3, 6]
      stage2: [128, 96, 512, 1, true, false, 3, 6]
      stage3: [512, 192, 1024, 3, true, true, 5, 6]
      stage4: [1024, 384, 2048, 1, true, true, 5, 6]
    hidden_size: 384
    pretrained_backbone: ./src/syntex/formula_net/formulanet_encoder_hgnetv2.pt
    freeze_backbone: true
  decoder:
    vocab_size: 687
    max_position_embeddings: 1024
    d_model: ${model.encoder.hidden_size}
    decoder_layers: 2
    decoder_attention_heads: 16
    decoder_ffn_dim: 1536
    bos_token_id: 2
    eos_token_id: 3
    pad_token_id: 0
    forced_eos_token_id: ${model.decoder.eos_token_id}
    layer_norm_eps: 1e-5
    is_decoder: true
    tie_word_embeddings: false

training:
  max_epochs: 10
  lr_scheduler:
    min_lr: 1e-8
    num_training_steps: 3e5
    num_warmup_steps: 5e3
  optimizer:
    lr: 1e-4
    betas: [0.9, 0.999]
    weight_decay: 0.05
  resume_from_ckpt: null

data:
  train_dataset_path: ./data/dataset/hf_dataset
  eval_image_dir: ./data/dataset/UniMER-Test/cpe
  eval_text_path: ./data/dataset/UniMER-Test/cpe.txt
  test_image_dir: ${data.eval_image_dir}
  test_text_path: ${data.eval_text_path}
  image_processor:
    image_size:
      width: 384
      height: 384
  text_processor:
    tokenizer_path: ./data/tokenizer
    tokenizer_config:
      add_special_tokens: true
      max_length: 1024
      padding: longest
      truncation: true
      return_tensors: pt
      return_attention_mask: true
      pad_to_multiple_of: 8
  train_batch_size: 64
  val_batch_size: 64
  test_batch_size: 8
  num_workers: 10
  sampling_strategy: null

trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${output_dir}
  accelerator: gpu
  devices: 1
  num_nodes: 1
  precision: bf16-mixed
  log_every_n_steps: 50
  max_epochs: 10
  val_check_interval: 1000
  profiler: null
  # gradient_clip_val: 2.0
  # gradient_clip_algorithm: norm

  callbacks:
    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      filename: "{step}-{val_loss:.4e}-{BLEU:.4f}-{edit_distance:.4f}"
      save_top_k: 10
      save_last: true
      monitor: "val_loss"
      mode: "min"
      every_n_epochs: 1

    - _target_: lightning.pytorch.callbacks.RichModelSummary
      max_depth: 3

    # - _target_: lightning.pytorch.callbacks.RichProgressBar
    #   refresh_rate: 5

    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: "step"

  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: ${output_dir}
    name: ""
    version: ""
    sub_dir: "tb_logs"
