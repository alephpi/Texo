output_dir: ${hydra:runtime.output_dir}

hydra:
  job:
    name: bs=${data.train_batch_size}-lr=${training.optimizer.lr}-decoder_layers=${model.decoder.decoder_layers}-hidden_size=${model.decoder.d_model}
  run:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}


# adapted from PPHGNetV2 and PPHGNetV2_B4_Formula
tokenizer_path: ./data/tokenizer
model:
  encoder:
    model_type: my_hgnetv2
    stem_channels: [3, 32, 48]
    stage_config:
      stage1: [48, 48, 128, 1, 6, 3, false, false]
      stage2: [128, 96, 512, 1, 6, 3, true, false]
      stage3: [512, 192, 1024, 3, 6, 5, true, true]
      stage4: [1024, 384, 2048, 1, 6, 5, true, true]
    hidden_size: 2048
    pretrained: ./src/syntex/formula_net/formulanet_encoder_hgnetv2.pt
    freeze: true
  decoder:
    model_type: mbart
    vocab_size: 687
    max_position_embeddings: 1024
    d_model: 384
    decoder_layers: 2
    decoder_attention_heads: 16
    decoder_ffn_dim: ${eval:'4*${model.decoder.d_model}'}
    bos_token_id: 2
    eos_token_id: 3
    pad_token_id: 0
    decoder_start_token_id: ${model.decoder.bos_token_id}
    forced_eos_token_id: ${model.decoder.eos_token_id}
    layer_norm_eps: 1e-5
    is_decoder: true
    is_encoder_decoder: false
    add_cross_attention: true
    scale_embedding: true
    tie_word_embeddings: false

training:
  lr_scheduler:
    min_lr: 1e-8
    num_training_steps: ${trainer.max_steps}
    num_warmup_steps: 5e3
  optimizer:
    lr: 1e-4
    betas: [0.9, 0.999]
    weight_decay: 0.05
  resume_from_ckpt: null

data:
  train_dataset_path: ./data/dataset/hf_dataset
  eval_image_dir: ./data/dataset/UniMER-Test/cpe
  eval_text_path: ./data/dataset/UniMER-Test/cpe.txt
  test_image_dir: ${data.eval_image_dir}
  test_text_path: ${data.eval_text_path}
  image_processor:
    image_size:
      width: 384
      height: 384
  text_processor:
    tokenizer_path: ${tokenizer_path}
    tokenizer_config:
      add_special_tokens: true
      max_length: 1024
      padding: longest
      truncation: true
      return_tensors: pt
      return_attention_mask: true
      pad_to_multiple_of: 8
  train_batch_size: 64
  val_batch_size: 64
  test_batch_size: 8
  num_workers: 10
  sampling_strategy: null

trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${output_dir}
  accelerator: gpu
  devices: 1
  num_nodes: 1
  precision: bf16-mixed
  log_every_n_steps: 50
  max_steps: 3e5
  val_check_interval: 1000
  profiler: null
  # gradient_clip_val: 2.0
  # gradient_clip_algorithm: norm

  callbacks:
    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      filename: "{step}-{val_loss:.4e}-{BLEU:.4f}-{edit_distance:.4f}"
      save_top_k: 10
      save_last: true
      monitor: "val_loss"
      mode: "min"
      every_n_epochs: 1

    - _target_: lightning.pytorch.callbacks.RichModelSummary
      max_depth: 3

    # - _target_: lightning.pytorch.callbacks.RichProgressBar
    #   refresh_rate: 5

    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: "step"

  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: ${output_dir}
    name: ""
    version: ""
    sub_dir: "tb_logs"
